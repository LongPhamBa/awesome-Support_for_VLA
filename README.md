[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)
# awesome-VLA

## ​ Paper

- [2024] OpenVLA: An Open-Source Vision-Language-Action Model [paper](https://arxiv.org/abs/2406.09246) [project](https://github.com/reazon-research/openvla)

- [2025] Fine-Tuning Vision-Language-Action Models: Optimizing Speed and Success [paper](https://arxiv.org/abs/2502.19645) [project](https://openvla-oft.github.io)

- [2024] TinyVLA: Towards Fast, Data-Efficient Vision-Language-Action Models for Robotic Manipulation [paper](https://arxiv.org/abs/2409.12514) [project](https://tiny-vla.github.io)

- [2025] MuBlE: MuJoCo and Blender simulation Environment and Benchmark for Task Planning in Robot Manipulation [paper](https://arxiv.org/abs/2503.02834)

- [2024] NaVILA: Legged Robot Vision-Language-Action Model for Navigation [paper](https://arxiv.org/abs/2412.04453)

- [2024] DextrAH-RGB: Visuomotor Policies to Grasp Anything with Dexterous Hands [paper](https://dextrah-rgb.github.io) [project](https://dextrah-rgb.github.io)

- [–] DeepWiki — sinh ra từ deepwiki project (chưa rõ paper; là nền tảng wiki mở) [project](https://deepwiki.com/openvla/openvla)

- [–] Robosuite: A Modular Simulation Framework and Benchmark for Robot Learning (không phải paper VLA) [project](https://robosuite.ai)
